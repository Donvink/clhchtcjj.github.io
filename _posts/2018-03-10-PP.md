---
layout: post
title:  投影寻踪
categories: machine-learning
author: CC
tags: machine-learning
---

# 投影寻踪——projection pursuit

## 1. 基本原理

投影寻踪是用来分析和处理高维数据，尤其是来自非正态总体的高维数据的一类统计方法。

**基本思想：**把高维数据通过某种组合，投影到低维（1-3维度）的子空间上，并通过极小化某个投影指标，寻找能够反映高维数据结构或特征的投影，在低维空间上对数据结构进行分析，以达到研究和分析高维数据的目的。

**特点：**

- 降维，排除与数据结构和特征无关或关系很小的变量的干扰；
- 可以用来解决某些非线性的问题。PP虽然是以数据的线性投影为基础，**但它找的是线性投影中的非线性结构**，因此它可以用来解决一定程度的非线性问题，如多元非线性回归。

有些传统的多元分析方法可以看成是机械投影寻踪的特例。例如主成份分析，判别分析等，但是主成分分析方法是用主成分来描述或逼近原始数据，所反映的是数据的全局特征或宏观特征，这样显然就有可能会漏掉主要的局部特征或细节特征。

PP的出发点是度量投影分布中所含信息的多少，而我们知道高维数据集合的线性投影几乎是正态的，并且正态分布通常为无信息分布的代表。从而寻找与正态分布差异最大的线性投影分布，即含信息量最多的投影分布，成为PP方法的常用方式之一。

**一般方案：**

- 选定一个分布模型作为标准（一般是正态分布），认为它是最不感兴趣的结构；
- 将数据投影到低维空间上，找出数据与标准模型相差最大的投影，这表明在投影中含有标准模型没能反映出的结构；
- 将上述投影中包含的结构从原始数据中剔除，得到改进后的新数据；
- 对新的数据重复上述第二和第三步骤，直到数据与标准模型在任何投影空间都没有明显的差异为止。

**常用的投影指标**：

- 方差指标，

  ​					$Q({\bf{a}}^TX)=\frac{1}{n}\sum_{i=1}^n({\bf{a}}^Tx_i-E({\bf{a}}^TX))$

  最大化这个指标，能求得最好的投影分布。主成分分析就是取样本方差为投影指标的PP方法。

- Friedman指标

- 偏度指标和峰度指标

- 信息散度指标



## 2. 投影寻踪聚类模型

**基本思想：**综合投影指标时，要求投影值的散布特征为：局部投影点尽可能密集，最好能凝聚成若干个点团，而在整体上投影团之间能尽可能散开。故可以将目标函数$Q({\bf{a}}^TX)$定义成类间距离$S({\bf{a}}^TX)$和类内密度$D({\bf{a}}^TX)$的乘积，最大化$Q$。

类间距离用样本序列的投影特征值的方差计算（令${\bf{z}}_i = {\bf{a}}^Tx_i$）：

​							$S({\bf{a}}^TX)=[\sum_{i=1}^n[{\bf{z}}_i-E(Z)]^2/(n-1)]^{1/2}$

类内密度：

​							$D({\bf{a}}^TX)=\sum_i^n\sum_j^n(R-r_{ij})\times I(R-r_{ij})$

其中。$R$是根据数据特征确定的局部宽度参数，其一般值选择$0.1*S$。$I$为示性函数，当$r_{ij}$小于等于$R$时，按类内计算，其值1。否则，其值为0

最终根据最优投影方向，便可以计算反映各指标综合信息的投影特征值的差异水平，对样本进行聚类分析。



